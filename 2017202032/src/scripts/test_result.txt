We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.Based on an analysis of the DMN, we propose several improvements to its memory and input modules.We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image description and retrieval problems, and video narration challenges.Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.RPNs are trained end-to-end to generate highquality region proposals, which are used by Fast R-CNN for detection.The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks.For each update, one set of weights is used to determine the greedy policy and the other to determine its value.We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classiÔ¨Åcation and Twitter sentiment prediction by distant supervision.