# Human Eye - Task 7

 2017202090 Liu Yifan

## Problem Definition

Given a picture $I$, the purpose of this problem is to generate a series of words $X=\{x_1, x_2, x_3, ..., x_N\}$ which can describe the given picture $I$ reasonably. 

## Baseline Method

The baseline idea is based on *Show & Tell： A Neural Image Caption Generator*. The method showed in the paper is a supervised learning method by using large dataset which has pairs of images and descriptions to train a generative model. The general idea is to extract features from image using CNN and then put the features and word embeddings of the corresponding description into a RNN.  

### Dataset

1. MS-COCO 2017 

   Training Set: 118,287 images (each image with 5 descriptions)

   Validation Set: 5000 images

2. Google conceptual captions 

   Training Set: 3,318,333 images (each image with 1 description)

### Data Preprocess

We need to apply preprocess to both image data and text data(the caption of the related image) in both training phase and inference phase.

- For **Image**, apply data augmentation(such as random crop, random flip and so on)
- For **Text**:
  1. Remove infrequent words (frequency < 5) to build vocabulary.
  2.  Word embedding to get the representation of each word. (Embedding Size = 300, the default embedding size of *spaCy* language model)
  3. Do sequence padding. 

### Model

The model has two parts, the first one is a convolution neural network serving as an **Encoder** which is used to extract features from images, and the second part is a recurrent neural network serving as a **Decoder** to generate the reasonable sequence.

**Encoder**

Use inception_v3 pretrained model with the top layer retrained based on training dataset.

Trainable parameters: weights of the top fully connected layer.

**Decoder**

Use 1-layer LSTM and one linear layer as the decoder

Input sequence: 

​	$x_0$ is the extracted features from the encoder above.

​	$X=\{x_1, x_2, x_3 ...x_N\}$ is the embedding sequence of the given image.

Trainable parameters: LSTM parameters (the embeddings are derived from spaCy lanuage model and here are set to be not trainable)

### Training Phase

The goal of training phase is to maximize the joint probability which describes the occurrence of the given text sequence.

**Loss function**: use cross entropy loss

**Optimizer**: Adam optimizer

### Inference Phase

The goal of inference phase is to generate sequence of words to describe the given picture.

Input & Output:

​	$x_0$ is the extracted features from encoder.

​	$x_1$ is the output of decoder when input is $x_0$.

​	$x_2$ is the output of decoder when input is $x_1$.

​	...

​	Until the inferred sequence meet `<END>` symbol or the length of the inferred sequence meets `max_length`.

As for the criterion for deciding which word to choose for next inference step, now this method uses **Greedy Search** (just choose the word having maximum occurrence probability). The future method will apply **Beam Search** as well.